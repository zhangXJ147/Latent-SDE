data:
    dataset: "male2female"
    image_size: 256
    channels: 3

model:
    image_size: 64
    latent_before_quant_conv: False
    VQGAN:
        params:
            ckpt_path: 'pretrained_model/VQGAN/model_f4.ckpt'
            embed_dim: 3
            n_embed: 8192
            ddconfig:
                double_z: false
                z_channels: 3
                resolution: 256
                in_channels: 3
                out_ch: 3
                ch: 128
                ch_mult: !!python/tuple
                    - 1
                    - 2
                    - 4
                num_res_blocks: 2
                attn_resolutions: [ ]
                dropout: 0.0

            lossconfig:
                target:
                    torch.nn.Identity
    type: "simple"
    in_channels: 3
    out_ch: 3
    num_channels: 128
    channel_mult: [1, 2, 3, 4]
    num_res_blocks: 2
    attention_resolutions: [16, ]
    dropout: 0.0
    var_type: fixedsmall
    resamp_with_conv: True
    learn_sigma: True
    class_cond: False
    num_heads: 4
    num_head_channels: 64
    num_heads_upsample: -1
    use_scale_shift_norm: True
    resblock_updown: True
    use_fp16: False
    use_new_attention_order: False
    num_class: 2

diffusion:
    beta_schedule: linear
    beta_start: 0.0001
    beta_end: 0.02
    num_diffusion_timesteps: 1000

dse:
    num_class : 2
    classifier_use_fp16: False
    classifier_width : 128
    classifier_depth : 4
    classifier_attention_resolutions: '32,16,8'
    classifier_use_scale_shift_norm: True
    classifier_resblock_updown: True
    classifier_pool: 'attention'
    classifier_scale: 1.0
    classifier_path: 'pretrained_model/dse_male2female_64x64.pt'